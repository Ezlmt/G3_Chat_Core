# å¾®è°ƒWhisperè¯­éŸ³è¯†åˆ«æ¨¡å‹å’ŒåŠ é€Ÿæ¨ç†

ç®€ä½“ä¸­æ–‡ | [English](./README_en.md)

![python version](https://img.shields.io/badge/python-3.8+-orange.svg)
![GitHub forks](https://img.shields.io/github/forks/yeyupiaoling/Whisper-Finetune)
![GitHub Repo stars](https://img.shields.io/github/stars/yeyupiaoling/Whisper-Finetune)
![GitHub](https://img.shields.io/github/license/yeyupiaoling/Whisper-Finetune)
![æ”¯æŒç³»ç»Ÿ](https://img.shields.io/badge/æ”¯æŒç³»ç»Ÿ-Win/Linux/MAC-9cf)

## å‰è¨€

OpenAIåœ¨å¼€æºäº†å·ç§°å…¶è‹±æ–‡è¯­éŸ³è¾¨è¯†èƒ½åŠ›å·²è¾¾åˆ°äººç±»æ°´å‡†çš„Whisperé¡¹ç›®ï¼Œä¸”å®ƒäº¦æ”¯æŒå…¶å®ƒ98ç§è¯­è¨€çš„è‡ªåŠ¨è¯­éŸ³è¾¨è¯†ã€‚Whisperæ‰€æä¾›çš„è‡ªåŠ¨è¯­éŸ³è¯†ä¸ç¿»è¯‘ä»»åŠ¡ï¼Œå®ƒä»¬èƒ½å°†å„ç§è¯­è¨€çš„è¯­éŸ³å˜æˆæ–‡æœ¬ï¼Œä¹Ÿèƒ½å°†è¿™äº›æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ã€‚æœ¬é¡¹ç›®ä¸»è¦çš„ç›®çš„æ˜¯ä¸ºäº†å¯¹Whisperæ¨¡å‹ä½¿ç”¨Loraè¿›è¡Œå¾®è°ƒï¼Œ**æ”¯æŒæ— æ—¶é—´æˆ³æ•°æ®è®­ç»ƒï¼Œæœ‰æ—¶é—´æˆ³æ•°æ®è®­ç»ƒã€æ— è¯­éŸ³æ•°æ®è®­ç»ƒ**ã€‚ç›®å‰å¼€æºäº†å¥½å‡ ä¸ªæ¨¡å‹ï¼Œå…·ä½“å¯ä»¥åœ¨[openai](https://huggingface.co/openai)æŸ¥çœ‹ï¼Œä¸‹é¢åˆ—å‡ºäº†å¸¸ç”¨çš„å‡ ä¸ªæ¨¡å‹ã€‚å¦å¤–é¡¹ç›®æœ€åè¿˜æ”¯æŒCTranslate2åŠ é€Ÿæ¨ç†å’ŒGGMLåŠ é€Ÿæ¨ç†ï¼Œæç¤ºä¸€ä¸‹ï¼ŒåŠ é€Ÿæ¨ç†æ”¯æŒç›´æ¥ä½¿ç”¨WhisperåŸæ¨¡å‹è½¬æ¢ï¼Œå¹¶ä¸ä¸€å®šéœ€è¦å¾®è°ƒã€‚æ”¯æŒWindowsæ¡Œé¢åº”ç”¨ï¼ŒAndroidåº”ç”¨å’ŒæœåŠ¡å™¨éƒ¨ç½²ã€‚

### è¯·å…ˆç‚¹ :star: 
## ğŸ”„ æœ€æ–°æ›´æ–°
* [2024/03/11] å‘å¸ƒBelle-whisper-large-v3-zhï¼ŒåŸºäºwhisper-large-v3æå‡ä¸­æ–‡è¯†åˆ«èƒ½åŠ›ï¼Œå¤æ‚åœºæ™¯è¯†åˆ«èƒ½åŠ›æ˜¾è‘—æå‡ã€‚
* [2023/12/29] å‘å¸ƒBelle-whisper-large-v2-zhï¼ŒåŸºäºwhisper-large-v2æå‡ä¸­æ–‡è¯†åˆ«èƒ½åŠ›ï¼Œä¸­æ–‡è¯†åˆ«èƒ½åŠ›æ˜¾è‘—æå‡ã€‚
* [2023/12/29] å‘å¸ƒBelle-distilwhisper-large-v2-zhï¼ŒåŸºäºdistilwhisper-large-v2æå‡ä¸­æ–‡è¯†åˆ«èƒ½åŠ›ï¼Œå…¼é¡¾é€Ÿåº¦å’Œç²¾åº¦ã€‚
 
## æ”¯æŒæ¨¡å‹

- openai/whisper-large-v2
- openai/whisper-large-v3
- distil-whisper

**ä½¿ç”¨ç¯å¢ƒï¼š**

- Anaconda 3
- Python 3.10
- Pytorch 2.1.0
- GPU A100-PCIE-80GB


## ç›®å½•
 - [é¡¹ç›®ä¸»è¦ç¨‹åºä»‹ç»](#é¡¹ç›®ä¸»è¦ç¨‹åºä»‹ç»)
 - [æ¨¡å‹è¯´æ˜](#æ¨¡å‹è¯´æ˜)
 - [æ¨¡å‹æ•ˆæœ](#æ¨¡å‹æ•ˆæœ)
 - [å®‰è£…ç¯å¢ƒ](#å®‰è£…ç¯å¢ƒ)
 - [å‡†å¤‡æ•°æ®](#å‡†å¤‡æ•°æ®)
 - [å¾®è°ƒæ¨¡å‹](#å¾®è°ƒæ¨¡å‹)
   - [å•å¡è®­ç»ƒ](#å•å¡è®­ç»ƒ)
   - [å¤šå¡è®­ç»ƒ](#å¤šå¡è®­ç»ƒ)
 - [åˆå¹¶æ¨¡å‹](#åˆå¹¶æ¨¡å‹)
 - [è¯„ä¼°æ¨¡å‹](#è¯„ä¼°æ¨¡å‹)
 - [é¢„æµ‹](#é¢„æµ‹)
 - [åŠ é€Ÿé¢„æµ‹](#åŠ é€Ÿé¢„æµ‹)
 - [GUIç•Œé¢é¢„æµ‹](#GUIç•Œé¢é¢„æµ‹)
 - [Webéƒ¨ç½²](#Webéƒ¨ç½²)
   - [æ¥å£æ–‡æ¡£](#æ¥å£æ–‡æ¡£)
 - [Androidéƒ¨ç½²](#Androidéƒ¨ç½²)
 - [Windowsæ¡Œé¢åº”ç”¨](#Windowsæ¡Œé¢åº”ç”¨)

<a name='é¡¹ç›®ä¸»è¦ç¨‹åºä»‹ç»'></a>

## é¡¹ç›®ä¸»è¦ç¨‹åºä»‹ç»

1. `aishell.py`ï¼šåˆ¶ä½œAIShellè®­ç»ƒæ•°æ®ã€‚
2. `finetune.py`ï¼šPEFTæ–¹å¼å¾®è°ƒæ¨¡å‹ã€‚
3. `finetune_all.py`ï¼šå…¨å‚æ•°å¾®è°ƒæ¨¡å‹ã€‚
4. `merge_lora.py`ï¼šåˆå¹¶Whisperå’ŒLoraçš„æ¨¡å‹ã€‚
5. `evaluation.py`ï¼šè¯„ä¼°ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹æˆ–è€…WhisperåŸæ¨¡å‹ã€‚
6. `infer_tfs.py`ï¼šä½¿ç”¨transformersç›´æ¥è°ƒç”¨å¾®è°ƒåçš„æ¨¡å‹æˆ–è€…WhisperåŸæ¨¡å‹é¢„æµ‹ï¼Œåªé€‚åˆæ¨ç†çŸ­éŸ³é¢‘ã€‚
7. `infer_ct2.py`ï¼šä½¿ç”¨è½¬æ¢ä¸ºCTranslate2çš„æ¨¡å‹é¢„æµ‹ï¼Œä¸»è¦å‚è€ƒè¿™ä¸ªç¨‹åºç”¨æ³•ã€‚
8. `infer_gui.py`ï¼šæœ‰GUIç•Œé¢æ“ä½œï¼Œä½¿ç”¨è½¬æ¢ä¸ºCTranslate2çš„æ¨¡å‹é¢„æµ‹ã€‚
9. `infer_server.py`ï¼šä½¿ç”¨è½¬æ¢ä¸ºCTranslate2çš„æ¨¡å‹éƒ¨ç½²åˆ°æœåŠ¡å™¨ç«¯ï¼Œæä¾›ç»™å®¢æˆ·ç«¯è°ƒç”¨ã€‚
10. `convert-ggml.py`ï¼šè½¬æ¢æ¨¡å‹ä¸ºGGMLæ ¼å¼æ¨¡å‹ï¼Œç»™Androidåº”ç”¨æˆ–è€…Windowsåº”ç”¨ä½¿ç”¨ã€‚
11. `AndroidDemo`ï¼šè¯¥ç›®å½•å­˜æ”¾çš„æ˜¯éƒ¨ç½²æ¨¡å‹åˆ°Androidçš„æºç ã€‚
12. `WhisperDesktop`ï¼šè¯¥ç›®å½•å­˜æ”¾çš„æ˜¯Windowsæ¡Œé¢åº”ç”¨çš„ç¨‹åºã€‚


<a name='æ¨¡å‹è¯´æ˜'></a>
## æ¨¡å‹è¯´æ˜
|       Model      | Parameters(M) |Base Model|  Data (Re)Sample Rate   |                      Train Datasets         | Fine-tuning (full or peft) | 
|:----------------:|:-------:|:-------:|:-------:|:----------------------------------------------------------:|:-----------:|
| Belle-whisper-large-v2-zh | 1550 |whisper-large-v2| 16KHz | [AISHELL-1](https://openslr.magicdatatech.com/resources/33/) [AISHELL-2](https://www.aishelltech.com/aishell_2) [WenetSpeech](https://wenet.org.cn/WenetSpeech/) [HKUST](https://catalog.ldc.upenn.edu/LDC2005S15)  |   full fine-tuning   |    
| Belle-distil-whisper-large-v2-zh | 756 | distil-whisper-large-v2 | 16KHz | [AISHELL-1](https://openslr.magicdatatech.com/resources/33/) [AISHELL-2](https://www.aishelltech.com/aishell_2) [WenetSpeech](https://wenet.org.cn/WenetSpeech/) [HKUST](https://catalog.ldc.upenn.edu/LDC2005S15)  |   full fine-tuning    |    
| Belle-whisper-large-v3-zh | 1550 |whisper-large-v3 | 16KHz | [AISHELL-1](https://openslr.magicdatatech.com/resources/33/) [AISHELL-2](https://www.aishelltech.com/aishell_2) [WenetSpeech](https://wenet.org.cn/WenetSpeech/) [HKUST](https://catalog.ldc.upenn.edu/LDC2005S15)  |   full fine-tuning   |    

<a name='æ¨¡å‹æ•ˆæœ'></a>

## æ¨¡å‹æ•ˆæœ CER(%) â†“
|      Model       |  Language Tag   | aishell_1 test |aishell_2 test| wenetspeech test_net | wenetspeech test_meeting | HKUST_dev| Model Link |
|:----------------:|:-------:|:-----------:|:-----------:|:--------:|:-----------:|:-------:|:-------:|
| whisper-large-v2 | Chinese |   8.818   | 6.183  |   12.343  |  26.413  | 31.917 | [HF](https://huggingface.co/openai/whisper-large-v2)|
| Belle-whisper-large-v2-zh | Chinese |   **2.549**    | **3.746**  |   **8.503**   | 14.598 | **16.289** |[HF](https://huggingface.co/BELLE-2/Belle-whisper-large-v2-zh) |
| whisper-large-v3 | Chinese |   8.085   | 5.475  |   11.72  |  20.15  | 28.597 | [HF](https://huggingface.co/openai/whisper-large-v3)|
| Belle-whisper-large-v3-zh | Chinese |   2.781    | 3.786 |   8.865   | **11.246** | 16.440 |[HF](https://huggingface.co/BELLE-2/Belle-whisper-large-v3-zh) |
| distil-whisper-large-v2 | Chinese |  -    | -  |   -  | - | -|[HF](https://huggingface.co/distil-whisper/distil-large-v2) |
| Belle-distilwhisper-large-v2-zh | Chinese |  5.958   | 6.477  |   12.786    | 17.039 | 20.771 | [HF](https://huggingface.co/BELLE-2/Belle-distilwhisper-large-v2-zh) |



**é‡è¦è¯´æ˜ï¼š**
1. åœ¨è¯„ä¼°çš„æ—¶å€™ç§»é™¤æ¨¡å‹è¾“å‡ºçš„æ ‡ç‚¹ç¬¦å·ï¼Œå¹¶æŠŠç¹ä½“ä¸­æ–‡è½¬æˆç®€ä½“ä¸­æ–‡ã€‚
2. `aishell_1_test`ä¸ºAIShell-1çš„æµ‹è¯•é›†ï¼Œ`aishell_2_test`ä¸ºAIShell-2çš„æµ‹è¯•é›†ï¼Œ`test_net`å’Œ`test_meeting`ä¸ºWenetSpeechçš„æµ‹è¯•é›†ã€‚
3. å¾®è°ƒæ•°æ®å‡å»é™¤æ ‡ç‚¹ã€ä¸å¸¦æ—¶é—´æˆ³ã€‚
4. distil-whisper-large-v2åŸºäºè‹±æ–‡æ•°æ®è’¸é¦ï¼Œåªèƒ½è¾“å‡ºè‹±æ–‡ã€‚ It's important to note that the original distil-whisper-large-v2 cannot transcribe Chinese (it only outputs English).
5. Belle-whisper-large-v3-zh ç›¸æ¯”Belle-whisper-large-v2-zhï¼Œåœ¨å¤æ‚åœºæ™¯æœ‰æ˜æ˜¾ä¼˜åŠ¿ï¼Œåœ¨wenetspeech meetingä¸Šå–å¾—SOTAæ•ˆæœ
   
<a name='å®‰è£…ç¯å¢ƒ'></a>

## å®‰è£…ç¯å¢ƒ

- é¦–å…ˆå®‰è£…çš„æ˜¯Pytorchçš„GPUç‰ˆæœ¬ï¼Œä»¥ä¸‹ä»‹ç»ä¸¤ç§å®‰è£…Pytorchçš„æ–¹å¼ï¼Œåªéœ€è¦é€‰æ‹©ä¸€ç§å³å¯ã€‚

1. ä»¥ä¸‹æ˜¯ä½¿ç”¨Anacondaå®‰è£…Pytorchç¯å¢ƒï¼Œå¦‚æœå·²ç»å®‰è£…è¿‡äº†ï¼Œè¯·è·³è¿‡ã€‚
```shell
conda install pytorch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 pytorch-cuda=11.6 -c pytorch -c nvidia
```

2. ä»¥ä¸‹æ˜¯ä½¿ç”¨Dockeré•œåƒï¼Œæ‹‰å–ä¸€ä¸ªPytorchç¯å¢ƒçš„é•œåƒã€‚
```shell
sudo docker pull pytorch/pytorch:1.13.1-cuda11.6-cudnn8-devel
```

ç„¶åè¿›å…¥åˆ°é•œåƒä¸­ï¼ŒåŒæ—¶å°†å½“å‰è·¯å¾„æŒ‚è½½åˆ°å®¹å™¨çš„`/workspace`ç›®å½•ä¸‹ã€‚
```shell
sudo nvidia-docker run --name pytorch -it -v $PWD:/workspace pytorch/pytorch:1.13.1-cuda11.6-cudnn8-devel /bin/bash
```

- å®‰è£…æ‰€éœ€çš„ä¾èµ–åº“ã€‚

```shell
python -m pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

- Windowséœ€è¦å•ç‹¬å®‰è£…bitsandbytesã€‚
```shell
python -m pip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.40.1.post1-py3-none-win_amd64.whl
```

<a name='å‡†å¤‡æ•°æ®'></a>

## å‡†å¤‡æ•°æ®

è®­ç»ƒçš„æ•°æ®é›†å¦‚ä¸‹ï¼Œæ˜¯ä¸€ä¸ªjsonlinesçš„æ•°æ®åˆ—è¡¨ï¼Œä¹Ÿå°±æ˜¯æ¯ä¸€è¡Œéƒ½æ˜¯ä¸€ä¸ªJSONæ•°æ®ï¼Œæ•°æ®æ ¼å¼å¦‚ä¸‹ã€‚æœ¬é¡¹ç›®æä¾›äº†ä¸€ä¸ªåˆ¶ä½œAIShellæ•°æ®é›†çš„ç¨‹åº`aishell.py`ï¼Œæ‰§è¡Œè¿™ä¸ªç¨‹åºå¯ä»¥è‡ªåŠ¨ä¸‹è½½å¹¶ç”Ÿæˆå¦‚ä¸‹åˆ—æ ¼å¼çš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œ**æ³¨æ„ï¼š** è¿™ä¸ªç¨‹åºå¯ä»¥é€šè¿‡æŒ‡å®šAIShellçš„å‹ç¼©æ–‡ä»¶æ¥è·³è¿‡ä¸‹è½½è¿‡ç¨‹çš„ï¼Œå¦‚æœç›´æ¥ä¸‹è½½ä¼šéå¸¸æ…¢ï¼Œå¯ä»¥ä½¿ç”¨ä¸€äº›å¦‚è¿…é›·ç­‰ä¸‹è½½å™¨ä¸‹è½½è¯¥æ•°æ®é›†ï¼Œç„¶åé€šè¿‡å‚æ•°`--filepath`æŒ‡å®šä¸‹è½½çš„å‹ç¼©æ–‡ä»¶è·¯å¾„ï¼Œå¦‚`/home/test/data_aishell.tgz`ã€‚

**å°æç¤ºï¼š**
1. å¦‚æœä¸ä½¿ç”¨æ—¶é—´æˆ³è®­ç»ƒï¼Œå¯ä»¥ä¸åŒ…å«`sentences`å­—æ®µçš„æ•°æ®ã€‚
2. å¦‚æœåªæœ‰ä¸€ç§è¯­è¨€çš„æ•°æ®ï¼Œå¯ä»¥ä¸åŒ…å«`language`å­—æ®µæ•°æ®ã€‚
3. å¦‚æœè®­ç»ƒç©ºè¯­éŸ³æ•°æ®ï¼Œ`sentences`å­—æ®µä¸º`[]`ï¼Œ`sentence`å­—æ®µä¸º`""`ï¼Œ`language`å­—æ®µå¯ä»¥ä¸å­˜åœ¨ã€‚
4. æ•°æ®å¯ä»¥ä¸åŒ…å«æ ‡ç‚¹ç¬¦å·ï¼Œä½†å¾®è°ƒçš„æ¨¡å‹ä¼šæŸå¤±æ·»åŠ ç¬¦å·èƒ½åŠ›ã€‚

```json
{
   "audio": {
      "path": "dataset/0.wav"
   },
   "sentence": "è¿‘å‡ å¹´ï¼Œä¸ä½†æˆ‘ç”¨ä¹¦ç»™å¥³å„¿å‹å²ï¼Œä¹ŸåŠè¯´äº²æœ‹ä¸è¦ç»™å¥³å„¿å‹å²é’±ï¼Œè€Œæ”¹é€å‹å²ä¹¦ã€‚",
   "language": "Chinese",
   "sentences": [
      {
         "start": 0,
         "end": 1.4,
         "text": "è¿‘å‡ å¹´ï¼Œ"
      },
      {
         "start": 1.42,
         "end": 8.4,
         "text": "ä¸ä½†æˆ‘ç”¨ä¹¦ç»™å¥³å„¿å‹å²ï¼Œä¹ŸåŠè¯´äº²æœ‹ä¸è¦ç»™å¥³å„¿å‹å²é’±ï¼Œè€Œæ”¹é€å‹å²ä¹¦ã€‚"
      }
   ],
   "duration": 7.37
}
```

<a name='å¾®è°ƒæ¨¡å‹'></a>

## å¾®è°ƒæ¨¡å‹

å‡†å¤‡å¥½æ•°æ®ä¹‹åï¼Œå°±å¯ä»¥å¼€å§‹å¾®è°ƒæ¨¡å‹äº†ã€‚è®­ç»ƒæœ€é‡è¦çš„ä¸¤ä¸ªå‚æ•°åˆ†åˆ«æ˜¯ï¼Œ`--base_model`æŒ‡å®šå¾®è°ƒçš„Whisperæ¨¡å‹ï¼Œè¿™ä¸ªå‚æ•°å€¼éœ€è¦åœ¨[HuggingFace](https://huggingface.co/openai)å­˜åœ¨çš„ï¼Œè¿™ä¸ªä¸éœ€è¦æå‰ä¸‹è½½ï¼Œå¯åŠ¨è®­ç»ƒæ—¶å¯ä»¥è‡ªåŠ¨ä¸‹è½½ï¼Œå½“ç„¶ä¹Ÿå¯ä»¥æå‰ä¸‹è½½ï¼Œé‚£ä¹ˆ`--base_model`æŒ‡å®šå°±æ˜¯è·¯å¾„ï¼ŒåŒæ—¶`--local_files_only`è®¾ç½®ä¸ºTrueã€‚ç¬¬äºŒä¸ª`--output_path`æ˜¯æ˜¯è®­ç»ƒæ—¶ä¿å­˜çš„Loraæ£€æŸ¥ç‚¹è·¯å¾„ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨Loraæ¥å¾®è°ƒæ¨¡å‹ã€‚å¦‚æœæƒ³å­˜è¶³å¤Ÿçš„è¯ï¼Œæœ€å¥½å°†`--use_8bit`è®¾ç½®ä¸ºFalseï¼Œè¿™æ ·è®­ç»ƒé€Ÿåº¦å¿«å¾ˆå¤šã€‚å…¶ä»–æ›´å¤šçš„å‚æ•°è¯·æŸ¥çœ‹è¿™ä¸ªç¨‹åºã€‚

<a name='å•å¡è®­ç»ƒ'></a>

### å•å¡è®­ç»ƒ

å•å¡è®­ç»ƒå‘½ä»¤å¦‚ä¸‹ï¼ŒWindowsç³»ç»Ÿå¯ä»¥ä¸æ·»åŠ `CUDA_VISIBLE_DEVICES`å‚æ•°ã€‚
```shell
CUDA_VISIBLE_DEVICES=0 python finetune.py --base_model=openai/whisper-tiny --output_dir=output/
```

<a name='å¤šå¡è®­ç»ƒ'></a>

### å¤šå¡è®­ç»ƒ

å¤šå¡è®­ç»ƒæœ‰ä¸¤ç§æ–¹æ³•ï¼Œåˆ†åˆ«æ˜¯torchrunå’Œaccelerateï¼Œå¼€å‘è€…å¯ä»¥æ ¹æ®è‡ªå·±çš„ä¹ æƒ¯ä½¿ç”¨å¯¹åº”çš„æ–¹å¼ã€‚

1. ä½¿ç”¨torchrunå¯åŠ¨å¤šå¡è®­ç»ƒï¼Œå‘½ä»¤å¦‚ä¸‹ï¼Œé€šè¿‡`--nproc_per_node`æŒ‡å®šä½¿ç”¨çš„æ˜¾å¡æ•°é‡ã€‚
```shell
torchrun --nproc_per_node=2 finetune.py --base_model=openai/whisper-tiny --output_dir=output/
```

2. ä½¿ç”¨accelerateå¯åŠ¨å¤šå¡è®­ç»ƒï¼Œå¦‚æœæ˜¯ç¬¬ä¸€æ¬¡ä½¿ç”¨accelerateï¼Œè¦é…ç½®è®­ç»ƒå‚æ•°ï¼Œæ–¹å¼å¦‚ä¸‹ã€‚

é¦–å…ˆé…ç½®è®­ç»ƒå‚æ•°ï¼Œè¿‡ç¨‹æ˜¯è®©å¼€å‘è€…å›ç­”å‡ ä¸ªé—®é¢˜ï¼ŒåŸºæœ¬éƒ½æ˜¯é»˜è®¤å°±å¯ä»¥ï¼Œä½†æœ‰å‡ ä¸ªå‚æ•°éœ€è¦çœ‹å®é™…æƒ…å†µè®¾ç½®ã€‚
```shell
accelerate config
```

å¤§æ¦‚è¿‡ç¨‹å°±æ˜¯è¿™æ ·ï¼š
```
--------------------------------------------------------------------In which compute environment are you running?
This machine
--------------------------------------------------------------------Which type of machine are you using?
multi-GPU
How many different machines will you use (use more than 1 for multi-node training)? [1]:
Do you wish to optimize your script with torch dynamo?[yes/NO]:
Do you want to use DeepSpeed? [yes/NO]:
Do you want to use FullyShardedDataParallel? [yes/NO]:
Do you want to use Megatron-LM ? [yes/NO]: 
How many GPU(s) should be used for distributed training? [1]:2
What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:
--------------------------------------------------------------------Do you wish to use FP16 or BF16 (mixed precision)?
fp16
accelerate configuration saved at /home/test/.cache/huggingface/accelerate/default_config.yaml
```

é…ç½®å®Œæˆä¹‹åï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹é…ç½®ã€‚
```shell
accelerate env
```

å¼€å§‹è®­ç»ƒå‘½ä»¤å¦‚ä¸‹ã€‚
```shell
accelerate launch finetune.py --base_model=openai/whisper-tiny --output_dir=output/
```


è¾“å‡ºæ—¥å¿—å¦‚ä¸‹ï¼š
```shell
{'loss': 0.9098, 'learning_rate': 0.000999046843662503, 'epoch': 0.01}                                                     
{'loss': 0.5898, 'learning_rate': 0.0009970611012927184, 'epoch': 0.01}                                                    
{'loss': 0.5583, 'learning_rate': 0.0009950753589229333, 'epoch': 0.02}                                                  
{'loss': 0.5469, 'learning_rate': 0.0009930896165531485, 'epoch': 0.02}                                          
{'loss': 0.5959, 'learning_rate': 0.0009911038741833634, 'epoch': 0.03}
```

<a name='åˆå¹¶æ¨¡å‹'></a>

## åˆå¹¶æ¨¡å‹

PEFTæ–¹å¼å¾®è°ƒæ¨¡å‹å®Œæˆä¹‹åä¼šæœ‰ä¸¤ä¸ªæ¨¡å‹ï¼Œç¬¬ä¸€ä¸ªæ˜¯WhisperåŸºç¡€æ¨¡å‹ï¼Œç¬¬äºŒä¸ªæ˜¯Loraæ¨¡å‹ï¼Œéœ€è¦æŠŠè¿™ä¸¤ä¸ªæ¨¡å‹åˆå¹¶ä¹‹åæ‰èƒ½ä¹‹åçš„æ“ä½œã€‚è¿™ä¸ªç¨‹åºåªéœ€è¦ä¼ é€’ä¸¤ä¸ªå‚æ•°ï¼Œ`--lora_model`æŒ‡å®šçš„æ˜¯è®­ç»ƒç»“æŸåä¿å­˜çš„Loraæ¨¡å‹è·¯å¾„ï¼Œå…¶å®å°±æ˜¯æ£€æŸ¥ç‚¹æ–‡ä»¶å¤¹è·¯å¾„ï¼Œç¬¬äºŒä¸ª`--output_dir`æ˜¯åˆå¹¶åæ¨¡å‹çš„ä¿å­˜ç›®å½•ã€‚
```shell
python merge_lora.py --lora_model=output/whisper-tiny/checkpoint-best/ --output_dir=models/
```

<a name='è¯„ä¼°æ¨¡å‹'></a>

## è¯„ä¼°æ¨¡å‹

æ‰§è¡Œä»¥ä¸‹ç¨‹åºè¿›è¡Œè¯„ä¼°æ¨¡å‹ï¼Œæœ€é‡è¦çš„ä¸¤ä¸ªå‚æ•°åˆ†åˆ«æ˜¯ã€‚ç¬¬ä¸€ä¸ª`--model_path`æŒ‡å®šçš„æ˜¯åˆå¹¶åçš„æ¨¡å‹è·¯å¾„ï¼ŒåŒæ—¶ä¹Ÿæ”¯æŒç›´æ¥ä½¿ç”¨WhisperåŸæ¨¡å‹ï¼Œä¾‹å¦‚ç›´æ¥æŒ‡å®š`openai/whisper-large-v2`ï¼Œç¬¬äºŒä¸ªæ˜¯`--metric`æŒ‡å®šçš„æ˜¯è¯„ä¼°æ–¹æ³•ï¼Œä¾‹å¦‚æœ‰å­—é”™ç‡`cer`å’Œè¯é”™ç‡`wer`ã€‚**æç¤ºï¼š** æ²¡æœ‰å¾®è°ƒçš„æ¨¡å‹ï¼Œå¯èƒ½è¾“å‡ºå¸¦æœ‰æ ‡ç‚¹ç¬¦å·ï¼Œå½±å“å‡†ç¡®ç‡ã€‚å…¶ä»–æ›´å¤šçš„å‚æ•°è¯·æŸ¥çœ‹è¿™ä¸ªç¨‹åºã€‚
```shell
python evaluation.py --model_path=models/whisper-tiny-finetune --metric=cer
```

<a name='é¢„æµ‹'></a>

## é¢„æµ‹

æ‰§è¡Œä»¥ä¸‹ç¨‹åºè¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œè¿™ä¸ªä½¿ç”¨transformersç›´æ¥è°ƒç”¨å¾®è°ƒåçš„æ¨¡å‹æˆ–è€…WhisperåŸæ¨¡å‹é¢„æµ‹ï¼Œåªé€‚åˆæ¨ç†çŸ­éŸ³é¢‘ï¼Œé•¿è¯­éŸ³è¿˜æ˜¯å‚è€ƒ`infer_ct2.py`çš„ä½¿ç”¨æ–¹å¼ã€‚ç¬¬ä¸€ä¸ª`--audio_path`å‚æ•°æŒ‡å®šçš„æ˜¯è¦é¢„æµ‹çš„éŸ³é¢‘è·¯å¾„ã€‚ç¬¬äºŒä¸ª`--model_path`æŒ‡å®šçš„æ˜¯åˆå¹¶åçš„æ¨¡å‹è·¯å¾„ï¼ŒåŒæ—¶ä¹Ÿæ”¯æŒç›´æ¥ä½¿ç”¨WhisperåŸæ¨¡å‹ï¼Œä¾‹å¦‚ç›´æ¥æŒ‡å®š`openai/whisper-large-v2`ã€‚å…¶ä»–æ›´å¤šçš„å‚æ•°è¯·æŸ¥çœ‹è¿™ä¸ªç¨‹åºã€‚
```shell
python infer_tfs.py --audio_path=dataset/test.wav --model_path=models/whisper-tiny-finetune
```

<a name='åŠ é€Ÿé¢„æµ‹'></a>

## åŠ é€Ÿé¢„æµ‹

ä¼—æ‰€å‘¨çŸ¥ï¼Œç›´æ¥ä½¿ç”¨Whisperæ¨¡å‹æ¨ç†æ˜¯æ¯”è¾ƒæ…¢çš„ï¼Œæ‰€ä»¥è¿™é‡Œæä¾›äº†ä¸€ä¸ªåŠ é€Ÿçš„æ–¹å¼ï¼Œä¸»è¦æ˜¯ä½¿ç”¨äº†CTranslate2è¿›è¡ŒåŠ é€Ÿï¼Œé¦–å…ˆè¦è½¬æ¢æ¨¡å‹ï¼ŒæŠŠåˆå¹¶åçš„æ¨¡å‹è½¬æ¢ä¸ºCTranslate2æ¨¡å‹ã€‚å¦‚ä¸‹å‘½ä»¤ï¼Œ`--model`å‚æ•°æŒ‡å®šçš„æ˜¯åˆå¹¶åçš„æ¨¡å‹è·¯å¾„ï¼ŒåŒæ—¶ä¹Ÿæ”¯æŒç›´æ¥ä½¿ç”¨WhisperåŸæ¨¡å‹ï¼Œä¾‹å¦‚ç›´æ¥æŒ‡å®š`openai/whisper-large-v2`ã€‚`--output_dir`å‚æ•°æŒ‡å®šçš„æ˜¯è½¬æ¢åçš„CTranslate2æ¨¡å‹è·¯å¾„ï¼Œ`--quantization`å‚æ•°æŒ‡å®šçš„æ˜¯é‡åŒ–æ¨¡å‹å¤§å°ï¼Œä¸å¸Œæœ›é‡åŒ–æ¨¡å‹çš„å¯ä»¥ç›´æ¥å»æ‰è¿™ä¸ªå‚æ•°ã€‚
```shell
ct2-transformers-converter --model models/whisper-tiny-finetune --output_dir models/whisper-tiny-finetune-ct2 --copy_files tokenizer.json --quantization float16
```

æ‰§è¡Œä»¥ä¸‹ç¨‹åºè¿›è¡ŒåŠ é€Ÿè¯­éŸ³è¯†åˆ«ï¼Œ`--audio_path`å‚æ•°æŒ‡å®šçš„æ˜¯è¦é¢„æµ‹çš„éŸ³é¢‘è·¯å¾„ã€‚`--model_path`æŒ‡å®šçš„æ˜¯è½¬æ¢åçš„CTranslate2æ¨¡å‹ã€‚å…¶ä»–æ›´å¤šçš„å‚æ•°è¯·æŸ¥çœ‹è¿™ä¸ªç¨‹åºã€‚
```shell
python infer_ct2.py --audio_path=dataset/test.wav --model_path=models/whisper-tiny-finetune-ct2
```

è¾“å‡ºç»“æœå¦‚ä¸‹ï¼š
```shell
-----------  Configuration Arguments -----------
audio_path: dataset/test.wav
model_path: models/whisper-tiny-finetune-ct2
language: zh
use_gpu: True
use_int8: False
beam_size: 10
num_workers: 1
vad_filter: False
local_files_only: True
------------------------------------------------
[0.0 - 8.0]ï¼šè¿‘å‡ å¹´,ä¸ä½†æˆ‘ç”¨ä¹¦ç»™å¥³å„¿å‹ç¢,ä¹Ÿå…¨è¯´äº²æœ‹ä¸è¦ç»™å¥³å„¿å‹ç¢é’±,è€Œæ”¹é€å‹ç¢ä¹¦ã€‚
```

<a name='GUIç•Œé¢é¢„æµ‹'></a>

## GUIç•Œé¢é¢„æµ‹

è¿™é‡ŒåŒæ ·æ˜¯ä½¿ç”¨äº†CTranslate2è¿›è¡ŒåŠ é€Ÿï¼Œè½¬æ¢æ¨¡å‹æ–¹å¼çœ‹ä¸Šé¢æ–‡æ¡£ã€‚`--model_path`æŒ‡å®šçš„æ˜¯è½¬æ¢åçš„CTranslate2æ¨¡å‹ã€‚å…¶ä»–æ›´å¤šçš„å‚æ•°è¯·æŸ¥çœ‹è¿™ä¸ªç¨‹åºã€‚

```shell
python infer_gui.py --model_path=models/whisper-tiny-finetune-ct2
```

å¯åŠ¨åç•Œé¢å¦‚ä¸‹ï¼š

<div align="center">
<img src="./docs/images/gui.jpg" alt="GUIç•Œé¢" width="600"/>
</div>

<a name='Webéƒ¨ç½²'></a>

## Webéƒ¨ç½²

Webéƒ¨ç½²åŒæ ·æ˜¯ä½¿ç”¨äº†CTranslate2è¿›è¡ŒåŠ é€Ÿï¼Œè½¬æ¢æ¨¡å‹æ–¹å¼çœ‹ä¸Šé¢æ–‡æ¡£ã€‚`--host`æŒ‡å®šæœåŠ¡å¯åŠ¨çš„åœ°å€ï¼Œè¿™é‡Œè®¾ç½®ä¸º`0.0.0.0`ï¼Œå³ä»»ä½•åœ°å€éƒ½å¯ä»¥è®¿é—®ã€‚`--port`æŒ‡å®šä½¿ç”¨çš„ç«¯å£å·ã€‚`--model_path`æŒ‡å®šçš„æ˜¯è½¬æ¢åçš„CTranslate2æ¨¡å‹ã€‚`--num_workers`æŒ‡å®šæ˜¯ä½¿ç”¨å¤šå°‘ä¸ªçº¿ç¨‹å¹¶å‘æ¨ç†ï¼Œè¿™åœ¨Webéƒ¨ç½²ä¸Šå¾ˆé‡è¦ï¼Œå½“æœ‰å¤šä¸ªå¹¶å‘è®¿é—®æ˜¯å¯ä»¥åŒæ—¶æ¨ç†ã€‚å…¶ä»–æ›´å¤šçš„å‚æ•°è¯·æŸ¥çœ‹è¿™ä¸ªç¨‹åºã€‚

```shell
python infer_server.py --host=0.0.0.0 --port=5000 --model_path=models/whisper-tiny-finetune-ct2 --num_workers=2
```

### æ¥å£æ–‡æ¡£

ç›®å‰æä¾›ä¸¤ä¸ªæ¥å£ï¼Œæ™®é€šçš„è¯†åˆ«æ¥å£`/recognition`å’Œæµå¼è¿”å›ç»“æœ`/recognition_stream`ï¼Œæ³¨æ„è¿™ä¸ªæµå¼æ˜¯æŒ‡æµå¼è¿”å›è¯†åˆ«ç»“æœï¼ŒåŒæ ·æ˜¯ä¸Šä¼ å®Œæ•´çš„éŸ³é¢‘ï¼Œç„¶åæµå¼è¿”å›è¯†åˆ«ç»“æœï¼Œè¿™ç§æ–¹å¼é’ˆå¯¹é•¿è¯­éŸ³è¯†åˆ«ä½“éªŒéå¸¸å¥½ã€‚ä»–ä»¬çš„æ–‡æ¡£æ¥å£æ˜¯å®Œå…¨ä¸€è‡´çš„ï¼Œæ¥å£å‚æ•°å¦‚ä¸‹ã€‚

|     å­—æ®µ     | æ˜¯å¦å¿…é¡» |   ç±»å‹   |    é»˜è®¤å€¼     |              è¯´æ˜               |
|:----------:|:----:|:------:|:----------:|:-----------------------------:|
|   audio    |  æ˜¯   |  File  |            |           è¦è¯†åˆ«çš„éŸ³é¢‘æ–‡ä»¶            |
| to_simple  |  å¦   |  int   |     1      |            æ˜¯å¦ç¹ä½“è½¬ç®€ä½“            |
| remove_pun |  å¦   |  int   |     0      |           æ˜¯å¦ç§»é™¤æ ‡ç‚¹ç¬¦å·            |
|    task    |  å¦   | String | transcribe | è¯†åˆ«ä»»åŠ¡ç±»å‹ï¼Œæ”¯æŒtranscribeå’Œtranslate |
|  language  |  å¦   | String |     zh     |    è®¾ç½®è¯­è¨€ï¼Œç®€å†™ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨æ£€æµ‹è¯­è¨€     |


è¿”å›ç»“æœï¼š

|   å­—æ®µ    |  ç±»å‹  |      è¯´æ˜       |
|:-------:|:----:|:-------------:|
| results | list |    åˆ†å‰²çš„è¯†åˆ«ç»“æœ    |
| +result | str  |   æ¯ç‰‡åˆ†éš”çš„æ–‡æœ¬ç»“æœ   |
| +start  | int  | æ¯ç‰‡åˆ†éš”çš„å¼€å§‹æ—¶é—´ï¼Œå•ä½ç§’ |
|  +end   | int  | æ¯ç‰‡åˆ†éš”çš„ç»“æŸæ—¶é—´ï¼Œå•ä½ç§’ |
|  code   | int  |  é”™è¯¯ç ï¼Œ0å³ä¸ºæˆåŠŸè¯†åˆ«  |

ç¤ºä¾‹å¦‚ä¸‹ï¼š
```json
{
  "results": [
    {
      "result": "è¿‘å‡ å¹´,ä¸ä½†æˆ‘ç”¨ä¹¦ç»™å¥³å„¿å‹ç¢,ä¹Ÿå…¨è¯´äº²æœ‹ä¸è¦ç»™å¥³å„¿å‹ç¢é’±,è€Œæ”¹é€å‹ç¢ä¹¦ã€‚",
      "start": 0,
      "end": 8
    }
  ],
  "code": 0
}
```

ä¸ºäº†æ–¹ä¾¿ç†è§£ï¼Œè¿™é‡Œæä¾›äº†è°ƒç”¨Webæ¥å£çš„Pythonä»£ç ï¼Œä¸‹é¢çš„æ˜¯`/recognition`çš„è°ƒç”¨æ–¹å¼ã€‚
```python
import requests

response = requests.post(url="http://127.0.0.1:5000/recognition", 
                         files=[("audio", ("test.wav", open("dataset/test.wav", 'rb'), 'audio/wav'))],
                         json={"to_simple": 1, "remove_pun": 0, "language": "zh", "task": "transcribe"}, timeout=20)
print(response.text)
```

ä¸‹é¢çš„æ˜¯`/recognition_stream`çš„è°ƒç”¨æ–¹å¼ã€‚
```python
import json
import requests

response = requests.post(url="http://127.0.0.1:5000/recognition_stream",
                         files=[("audio", ("test.wav", open("dataset/test_long.wav", 'rb'), 'audio/wav'))],
                         json={"to_simple": 1, "remove_pun": 0, "language": "zh", "task": "transcribe"}, stream=True, timeout=20)
for chunk in response.iter_lines(decode_unicode=False, delimiter=b"\0"):
    if chunk:
        result = json.loads(chunk.decode())
        text = result["result"]
        start = result["start"]
        end = result["end"]
        print(f"[{start} - {end}]ï¼š{text}")
```


æä¾›çš„æµ‹è¯•é¡µé¢å¦‚ä¸‹ï¼š

é¦–é¡µ`http://127.0.0.1:5000/` çš„é¡µé¢å¦‚ä¸‹ï¼š

<div align="center">
<img src="./docs/images/web.jpg" alt="é¦–é¡µ" width="600"/>
</div>

æ–‡æ¡£é¡µé¢`http://127.0.0.1:5000/docs` çš„é¡µé¢å¦‚ä¸‹ï¼š

<div align="center">
<img src="./docs/images/api.jpg" alt="æ–‡æ¡£é¡µé¢" width="600"/>
</div>


<a name='Androidéƒ¨ç½²'></a>
## Androidéƒ¨ç½²

å®‰è£…éƒ¨ç½²çš„æºç åœ¨[AndroidDemo](./AndroidDemo)ç›®å½•ä¸‹ï¼Œå…·ä½“æ–‡æ¡£å¯ä»¥åˆ°è¯¥ç›®å½•ä¸‹çš„[README.md](AndroidDemo/README.md)æŸ¥çœ‹ã€‚
<br/>
<div align="center">
<img src="./docs/images/android2.jpg" alt="Androidæ•ˆæœå›¾" width="200">
<img src="./docs/images/android1.jpg" alt="Androidæ•ˆæœå›¾" width="200">
<img src="./docs/images/android3.jpg" alt="Androidæ•ˆæœå›¾" width="200">
<img src="./docs/images/android4.jpg" alt="Androidæ•ˆæœå›¾" width="200">
</div>


<a name='Windowsæ¡Œé¢åº”ç”¨'></a>
## Windowsæ¡Œé¢åº”ç”¨

ç¨‹åºåœ¨[WhisperDesktop](./WhisperDesktop)ç›®å½•ä¸‹ï¼Œå…·ä½“æ–‡æ¡£å¯ä»¥åˆ°è¯¥ç›®å½•ä¸‹çš„[README.md](WhisperDesktop/README.md)æŸ¥çœ‹ã€‚

<br/>
<div align="center">
<img src="./docs/images/desktop1.jpg" alt="Windowsæ¡Œé¢åº”ç”¨æ•ˆæœå›¾">
</div>



## å‚è€ƒèµ„æ–™

1. https://github.com/huggingface/peft
2. https://github.com/guillaumekln/faster-whisper
3. https://github.com/ggerganov/whisper.cpp
4. https://github.com/Const-me/Whisper
